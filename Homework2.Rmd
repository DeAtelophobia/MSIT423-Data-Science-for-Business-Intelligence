---
title: "Homework 2"
author: "De Lu"
date: "April 10, 2019"
output: html_document
---

```{r}
auto = read.table("http://www-bcf.usc.edu/~gareth/ISL/Auto.data",
header=T, na.strings="?")
auto$origin = factor(auto$origin, 1:3, c("US", "Europe", "Japan"))
Sauto = as.data.frame(scale(auto[,1:7]))

#(a) Regress mpg on cylinders, displacement, weight, and year. Comment on the signs of the estimated coecients and note which are signicantly dierent from 0. What is value of R2?
model1 = lm(mpg~ cylinders + displacement + weight + year, data = Sauto)
summary(model1)
```
According to the summary of the linear model, we can find that the coefficients of weight, year seems to be significant from 0.
R2 is 80.91%, while the adjusted R2 is 80.72%.

```{r}
#(b) Compute the variance in ation factors. What do they tell you?
library(car)
vif(model1)
```
According to the VIF, the cylinders and displacement have VIFs bigger than 10, indicating there may be other predictors in the model having multicollinearity relationship with them.

```{r}
#(c) Drop weight from the model. What happens to the parameter estimates and R2?
model1.1= lm(mpg~ cylinders + displacement + year, data = Sauto)
summary(model1.1)
```
The coefficient of dispalcement and year becomes siginificant, and the R2 decrase to 74.23%, the adjusted R2 decrease to 74.03%.

```{r}
#(d) Drop weight and displacement from the model. What happens to the parameter estimates and R2?
model1.2=lm(mpg~ cylinders + year, data= Sauto)
summary(model1.2)
```
The coefficient of cylinders and year become siginificant, the R2 keep decreasing to 71.35%, the adjusted R2 becomes 71.20%.

```{r}
#2.JWHT problem 3.14a-f on page 125. For part (c)-(e), are the parameters ‚Äúcovered‚Äù by the 95% confidence intervals? 
set.seed(1)
x1=runif(100)
x2=0.5*x1+rnorm(100)/10
y=2+2*x1+0.3*x2+rnorm(100)
model2=lm(y~x1+x2)
model2.1=lm(y~x1)
model2.2=lm(y~x2)
confint(model2)
confint(model2.1)
confint(model2.2)
```
From (c) to (e) we got three models. model2 included all the predictors, model2.1 included only x1, and model2.2 included only x2. The original model should be y=2+2x1+0.3x2+œµi. Accourding to the cofidence interval 95% calculated below, we find that:
model2: Œ≤1 is in (0.008,2.871),Œ≤2 is in (-1.24,3.26). Both cover parameters.
model2.1: Œ≤1 is in (1.654,2.57),Œ≤2 is in (1.1895,2.76), covering the Œ≤1, but not covering Œ≤2.
model2.2: Œ≤1 is in (2.003,2.77),Œ≤2 is in (1.64,4.16). Both not cover parameters.

```{r}
#2.
setwd("C:/Users/De_Lu/Desktop/2019 Spring/MSIT423 Data Science for Business Intelligence")
Data = read.csv(file="quality.csv")
quality = read.csv(file ="quality.csv")
Squality= as.data.frame(scale(quality[,1:5]))
deviance(lm(defect~1, quality))
deviance(lm(defect~rate, quality))
deviance(lm(defect~am , quality))
deviance(lm(defect~rate + am, quality))
```
(a) How much variance is left unexplained by the intercept model? (this will called the null deviance)
Ans:
According to the Rcode, when there is only intercept in model, the unexplained variance is 10929.29.

(b) How much variation is explained by adding rate to the intercept model?
Ans:
When there is rate in model, the explained variance is increased by 10929.29-2362.427=8566.863

(c) How much addtional variation is explained by adding am to a model that already has rate in it?
Ans:
When there is am in model, the explained variance is increased by 10929.29-7795.84=3133.45

(d) How much variation is unexplained by a moel having both predictors?
Ans:
When there are rate and am in model, the explained variance is increased by 10929.29-2355.319=8573.971

```{r}
#(e) How much less variation is explained if we drop rate from a model with both predictors in it?
model3=lm(defect~rate + am, quality)
drop1(model3, test="F")
```
Ans:
7795.8

```{r}
#(f) Compute R2 for the two-predictor model ‚Äúby hand‚Äù using only the numbers have found above. Confirm your answer by having R compute it.
# (TSS - RSS)/TSS =(10929.29-2362.4)/10929.29=78.39%
summary(model3)
anova(model3)
```
(8566.863)/(10929.29)=78.39%, the result from R is 78.45%.

```{r}
# (g) Compute the F statistic for the overall test of significance by hand.
((8566.863)/2)/((2355.319)/(30-2-1))
```
F=[8566.863/2]/[2355.319/(30‚àí2‚àí1)]=49.10 , nearly equal to 49.14 in R output.

```{r}
# (h) Using the two-variable model, compute the F statistic to test H0:Œ≤1=0 by hand (where Œ≤1 is for rate)
((5440.5)/1)/((2355.319)/(30-2-1))
1-pf(62.36671, 1, 27)
```

Ans:
(1) H0:Œ≤1=0,Ha:Œ≤3‚â†0.
F=5440.512355.330‚àí1‚àí1=62.367
p=1.724305√ó10‚àí8‚â§0.05, reject H0.